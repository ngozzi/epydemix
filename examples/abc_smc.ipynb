{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: Tolerance = 0.18814751212193076, Accepted Particles = 1000\n",
      "Generation 2: Tolerance = 0.1309726971134102, Accepted Particles = 1000\n",
      "Generation 3: Tolerance = 0.09167672716788353, Accepted Particles = 1000\n",
      "Generation 4: Tolerance = 0.06330579682749779, Accepted Particles = 1000\n",
      "Generation 5: Tolerance = 0.04412964593606952, Accepted Particles = 1000\n",
      "Generation 6: Tolerance = 0.031611003598288986, Accepted Particles = 1000\n",
      "Generation 7: Tolerance = 0.023142908731751816, Accepted Particles = 1000\n",
      "Generation 8: Tolerance = 0.016502317483896287, Accepted Particles = 1000\n",
      "Generation 9: Tolerance = 0.011838817000579718, Accepted Particles = 1000\n",
      "Generation 10: Tolerance = 0.008318342551507138, Accepted Particles = 1000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from scipy import stats\n",
    "\n",
    "def absolute_difference(data, simulation):\n",
    "    return np.abs(data - simulation)\n",
    "\n",
    "\n",
    "class ABCSMC:\n",
    "\n",
    "    def __init__(self, \n",
    "                 model, \n",
    "                 priors, \n",
    "                 parameters, \n",
    "                 observed_data, \n",
    "                 perturbation_kernel, \n",
    "                 distance_function = absolute_difference, \n",
    "                 p_discrete_transition : float = 0.3,\n",
    "                 num_particles : int = 1000, \n",
    "                 max_generations : int = 10, \n",
    "                 minimum_epsilon : float = 0.15, \n",
    "                 max_walltime : timedelta = None,\n",
    "                 include_quantiles : bool = True, \n",
    "                 dates_column=\"simulation_dates\"):\n",
    "        self.model = model\n",
    "        self.priors = priors\n",
    "        self.parameters = parameters\n",
    "        self.observed_data = observed_data\n",
    "        self.perturbation_kernel = perturbation_kernel\n",
    "        self.distance_function = distance_function\n",
    "        self.p_discrete_transition = p_discrete_transition\n",
    "        self.num_particles = num_particles\n",
    "        self.max_generations = max_generations\n",
    "        self.minimum_epsilon = minimum_epsilon\n",
    "        self.max_walltime = max_walltime\n",
    "        self.include_quantiles = include_quantiles\n",
    "        self.dates_column = dates_column\n",
    "        self.particles = None\n",
    "        self.weights = None\n",
    "        self.tolerance = None\n",
    "\n",
    "    def initialize_particles(self):\n",
    "        # Initialize particles from the prior\n",
    "        self.particles = [{p: priors[p].rvs() for p in priors} for _ in range(self.num_particles)]\n",
    "        self.weights = np.ones(self.num_particles) / self.num_particles\n",
    "        self.tolerance = np.inf\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        # get continuous and discrete parameters\n",
    "        continuous_params, discrete_params = [], []\n",
    "        for param in self.priors:\n",
    "            if isinstance(self.priors[param].dist, stats.rv_continuous):\n",
    "                continuous_params.append(param)\n",
    "            elif isinstance(self.priors[param].dist, stats.rv_discrete):\n",
    "                discrete_params.append(param)\n",
    "\n",
    "        self.initialize_particles()\n",
    "\n",
    "        for generation in range(self.max_generations):\n",
    "            # compute covariance matrix\n",
    "            cov_matrix = compute_covariance_matrix(self.particles, continuous_params)\n",
    "            \n",
    "            new_particles = []\n",
    "            new_weights = []\n",
    "            distances = []\n",
    "\n",
    "            total_accepted = 0\n",
    "            #for i in range(self.num_particles):\n",
    "            while total_accepted < self.num_particles:\n",
    "                # Perturb particle\n",
    "                i = np.random.choice(range(self.num_particles), p=self.weights)\n",
    "                #particle = self.perturbation_kernel(self.particles[i])\n",
    "                particle = perturbation_kernel(self.particles[i], continuous_params, discrete_params, cov_matrix, priors, self.p_discrete_transition)\n",
    "\n",
    "                # Simulate data from perturbed particle\n",
    "                full_params = {}\n",
    "                full_params.update(particle)\n",
    "                full_params.update(self.parameters)\n",
    "                simulated_data = self.model(full_params)\n",
    "\n",
    "                # Calculate distance\n",
    "                distance = self.distance_function(self.observed_data, simulated_data)\n",
    "                if distance < self.tolerance:\n",
    "                    new_particles.append(particle)\n",
    "                    distances.append(distance)\n",
    "                    #new_weights.append(self.weights[i])  # Assuming uniform weights for simplicity\n",
    "                    total_accepted += 1\n",
    "\n",
    "            # Normalize weights\n",
    "            #new_weights = np.array(new_weights)\n",
    "            #new_weights /= np.sum(new_weights)\n",
    "\n",
    "            # Update particles and weights\n",
    "            self.weights = compute_weights(new_particles, self.particles, self.weights, priors, cov_matrix, continuous_params, discrete_params, self.p_discrete_transition)\n",
    "            self.particles = new_particles\n",
    "\n",
    "            # Update tolerance for the next generation\n",
    "            self.tolerance = np.percentile(distances, 75)  # Median distance\n",
    "\n",
    "            print(f\"Generation {generation + 1}: Tolerance = {self.tolerance}, Accepted Particles = {len(new_particles)}\")\n",
    "\n",
    "            if len(new_particles) == 0:\n",
    "                print(\"No particles accepted in this generation. Stopping.\")\n",
    "                break\n",
    "\n",
    "        return self.particles, self.weights\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Define a simple model, prior_sampler, perturbation_kernel, and distance_function\n",
    "\n",
    "def model(parameters):\n",
    "    # Simple model example, e.g., particle directly represents simulated data\n",
    "    return parameters[\"beta\"] + parameters[\"mu\"]\n",
    "\n",
    "\n",
    "def perturbation_kernel(particle, continuous_params, discrete_params, cov_matrix, priors, p_discrete_transition):\n",
    "    \"\"\"\n",
    "    Perturbs a particle's parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - particle: dict, keys are parameter names, values are current values of the parameters\n",
    "    - continuous_params: list of parameter names that are continuous\n",
    "    - discrete_params: list of parameter names that are discrete\n",
    "    - cov_matrix: dict, covariance matrices for the continuous parameters\n",
    "    - priors: dict, prior distributions for the parameters\n",
    "    - discrete_jump_probs: dict, probability distributions for the discrete jumps\n",
    "\n",
    "    Returns:\n",
    "    - perturbed_particle: dict, the perturbed particle\n",
    "    \"\"\"\n",
    "    perturbed_particle = particle.copy()\n",
    "\n",
    "    # Perturb continuous parameters\n",
    "    if continuous_params:\n",
    "        # Extract current values for continuous parameters\n",
    "        current_values = np.array([particle[param] for param in continuous_params])\n",
    "\n",
    "        # Apply multivariate normal transition\n",
    "        perturbed_values = np.random.multivariate_normal(\n",
    "            mean=np.array(current_values),\n",
    "            cov=cov_matrix\n",
    "        )\n",
    "\n",
    "        # Update the perturbed particle with new continuous values\n",
    "        for i, param in enumerate(continuous_params):\n",
    "            perturbed_particle[param] = perturbed_values[i]\n",
    "\n",
    "    # Perturb discrete parameters\n",
    "    for param in discrete_params:\n",
    "    \n",
    "        current_value = particle[param]\n",
    "        # The probability distribution must exclude the current value if we are jumping to a different state\n",
    "        if np.random.rand() < p_discrete_transition:\n",
    "            # Get the probability distribution for the current parameter\n",
    "            perturbed_particle[param] = np.random.choice(range(priors[param].support()[0], priors[param].support()[1]))\n",
    "\n",
    "    return perturbed_particle\n",
    "\n",
    "\n",
    "def compute_covariance_matrix(particles, continuous_params):\n",
    "    \"\"\"\n",
    "    Computes the covariance matrix for the continuous parameters in a list of particles.\n",
    "\n",
    "    Parameters:\n",
    "    - particles: list of dicts, each dict contains a set of parameters\n",
    "    - continuous_params: list of str, the names of the continuous parameters\n",
    "\n",
    "    Returns:\n",
    "    - covariance_matrix: numpy array, the covariance matrix of the continuous parameters\n",
    "    \"\"\"\n",
    "    # Extract the values of the continuous parameters from each particle\n",
    "    data = np.array([[particle[param] for param in continuous_params] for particle in particles])\n",
    "\n",
    "    # Compute the covariance matrix\n",
    "    if len(continuous_params) == 1:\n",
    "        covariance_matrix = np.array([[np.var(data)]])\n",
    "    else:\n",
    "        covariance_matrix = np.cov(data, rowvar=False)\n",
    "\n",
    "    return covariance_matrix\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def compute_weights(new_particles, old_particles, old_weights, priors, cov_matrix, continuous_params, discrete_params, discrete_transition_prob):\n",
    "    \"\"\"\n",
    "    Computes the weights for new particles in generation t.\n",
    "    \n",
    "    Parameters:\n",
    "    - new_particles: list of dicts, the particles in the current generation t\n",
    "    - old_particles: list of dicts, the particles from the previous generation t-1\n",
    "    - old_weights: list of floats, the weights of particles from generation t-1\n",
    "    - priors: dict, keys are parameter names and values are scipy.stats objects representing the priors\n",
    "    - cov_matrix: covariance matrix used in the perturbation kernel for continuous parameters\n",
    "    - continuous_params: list of parameter names that are continuous\n",
    "    - discrete_params: list of parameter names that are discrete\n",
    "    - discrete_transition_prob: float, probability of any transition for discrete parameters\n",
    "    \n",
    "    Returns:\n",
    "    - new_weights: list of floats, the computed weights for the new particles\n",
    "    \"\"\"\n",
    "    # Precompute inverse and determinant of covariance matrix for the multivariate normal\n",
    "    #inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "    #log_det_cov_matrix = np.log(np.linalg.det(cov_matrix))\n",
    "\n",
    "    new_weights = np.zeros(len(new_particles))\n",
    "    \n",
    "    for i, new_particle in enumerate(new_particles):\n",
    "        # Compute the prior probability of the new particle\n",
    "        prior_prob = np.prod([priors[param].pdf(new_particle[param]) for param in continuous_params])\n",
    "        prior_prob *= np.prod([priors[param].pmf(new_particle[param]) for param in discrete_params])\n",
    "\n",
    "        # Compute the denominator of the weight expression\n",
    "        diff_vectors = np.array([[new_particle[param] - old_particle[param] for param in continuous_params] for old_particle in old_particles])\n",
    "        continuous_kernel_probs = multivariate_normal.logpdf(diff_vectors, mean=np.zeros(len(continuous_params)), cov=cov_matrix, allow_singular=True)\n",
    "\n",
    "        discrete_kernel_probs = np.ones(len(old_particles))\n",
    "        for param in discrete_params:\n",
    "            transitions = np.array([new_particle[param] != old_particle[param] for old_particle in old_particles])\n",
    "            discrete_kernel_probs *= np.where(transitions, discrete_transition_prob, 1 - discrete_transition_prob)\n",
    "\n",
    "        kernel_probs = np.exp(continuous_kernel_probs) * discrete_kernel_probs\n",
    "        denominator = np.sum(old_weights * kernel_probs)\n",
    "        \n",
    "        # Calculate the weight for the new particle\n",
    "        new_weights[i] = prior_prob / denominator\n",
    "\n",
    "    # Normalize the weights so they sum to 1\n",
    "    new_weights /= np.sum(new_weights)\n",
    "    \n",
    "    return new_weights\n",
    "\n",
    "\n",
    "priors = {\"beta\": stats.uniform(0.05, 0.3)}\n",
    "parameters = {\"mu\": 0.2}\n",
    "observed_data = 0.3\n",
    "\n",
    "abc_smc = ABCSMC(model, \n",
    "                 priors, \n",
    "                 parameters, \n",
    "                 observed_data, \n",
    "                 perturbation_kernel, \n",
    "                 distance_function = absolute_difference)\n",
    "\n",
    "\n",
    "final_particles, final_weights = abc_smc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111334</td>\n",
       "      <td>0.001224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095103</td>\n",
       "      <td>0.000951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.094481</td>\n",
       "      <td>0.000961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.098274</td>\n",
       "      <td>0.000919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111254</td>\n",
       "      <td>0.001218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.099950</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.097460</td>\n",
       "      <td>0.000923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.090750</td>\n",
       "      <td>0.001070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.090916</td>\n",
       "      <td>0.001064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         beta   weights\n",
       "0    0.111334  0.001224\n",
       "1    0.095103  0.000951\n",
       "2    0.094481  0.000961\n",
       "3    0.098274  0.000919\n",
       "4    0.111254  0.001218\n",
       "..        ...       ...\n",
       "995  0.099950  0.000917\n",
       "996  0.097460  0.000923\n",
       "997  0.090750  0.001070\n",
       "998  0.090916  0.001064\n",
       "999  0.109091  0.001100\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "posterior_dict = {}\n",
    "for param in priors.keys(): \n",
    "    posterior_dict[param] = [sample[param] for sample in final_particles]\n",
    "\n",
    "\n",
    "posterior_df = pd.DataFrame(posterior_dict) \n",
    "posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.arange(0, 100), 75) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(np.arange(0, 100), 0.75) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "import scipy\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Assuming priors, old_particles, old_weights, cov_matrix, continuous_params, and discrete_params are defined\n",
    "\n",
    "priors = {\n",
    "    'param1': scipy.stats.uniform(0, 1),  # Continuous: Uniform prior between 0 and 1\n",
    "    'param2': scipy.stats.norm(0.5, 0.1),  # Continuous: Normal prior with mean 0.5 and std 0.1\n",
    "    'param3': scipy.stats.randint(1, 4),  # Discrete: Discrete uniform prior over [1, 2, 3]\n",
    "    'param4': scipy.stats.bernoulli(0.6)  # Discrete: Bernoulli prior with p=0.6\n",
    "}\n",
    "\n",
    "old_particles = [\n",
    "    {'param1': 0.5, 'param2': 0.3, 'param3': 2, 'param4': 1},\n",
    "    {'param1': 0.6, 'param2': 0.4, 'param3': 3, 'param4': 0},\n",
    "    {'param1': 0.4, 'param2': 0.2, 'param3': 1, 'param4': 1}\n",
    "]\n",
    "\n",
    "old_weights = [0.3, 0.4, 0.3]\n",
    "\n",
    "new_particles = [\n",
    "    {'param1': 0.55, 'param2': 0.35, 'param3': 2, 'param4': 1},\n",
    "    {'param1': 0.45, 'param2': 0.25, 'param3': 1, 'param4': 0}\n",
    "]\n",
    "\n",
    "continuous_params = ['param1', 'param2']\n",
    "discrete_params = ['param3', 'param4']\n",
    "\n",
    "cov_matrix = np.array([\n",
    "    [0.01, 0],   # Covariance matrix for continuous parameters param1 and param2\n",
    "    [0, 0.01]\n",
    "])\n",
    "\n",
    "discrete_transition_prob = 0.1  # Example probability of transitioning between any two discrete states\n",
    "\n",
    "new_weights = compute_weights(new_particles, old_particles, old_weights, priors, cov_matrix, continuous_params, discrete_params, discrete_transition_prob)\n",
    "print(\"New Weights:\", new_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Weights: [0.60660834 0.39339166]\n"
     ]
    }
   ],
   "source": [
    "import scipy \n",
    "\n",
    "priors = {\n",
    "    'param1': scipy.stats.uniform(0, 1),  # Continuous: Uniform prior between 0 and 1\n",
    "    'param2': scipy.stats.norm(0.5, 0.1),  # Continuous: Normal prior with mean 0.5 and std 0.1\n",
    "    'param3': scipy.stats.randint(1, 4),  # Discrete: Discrete uniform prior over [1, 2, 3]\n",
    "    'param4': scipy.stats.bernoulli(0.6)  # Discrete: Bernoulli prior with p=0.6\n",
    "}\n",
    "\n",
    "old_particles = [\n",
    "    {'param1': 0.5, 'param2': 0.3, 'param3': 2, 'param4': 1},\n",
    "    {'param1': 0.6, 'param2': 0.4, 'param3': 3, 'param4': 0},\n",
    "    {'param1': 0.4, 'param2': 0.2, 'param3': 1, 'param4': 1}\n",
    "]\n",
    "\n",
    "old_weights = [0.3, 0.4, 0.3]\n",
    "\n",
    "new_particles = [\n",
    "    {'param1': 0.55, 'param2': 0.35, 'param3': 2, 'param4': 1},\n",
    "    {'param1': 0.45, 'param2': 0.25, 'param3': 1, 'param4': 0}\n",
    "]\n",
    "\n",
    "continuous_params = ['param1', 'param2']\n",
    "discrete_params = ['param3', 'param4']\n",
    "\n",
    "cov_matrix = np.array([\n",
    "    [0.01, 0],   # Covariance matrix for continuous parameters param1 and param2\n",
    "    [0, 0.01]\n",
    "])\n",
    "\n",
    "discrete_transition_prob = 0.1  # Example probability of transitioning between any two discrete states\n",
    "\n",
    "new_weights = compute_weights(new_particles, old_particles, old_weights, priors, cov_matrix, continuous_params, discrete_params, discrete_transition_prob)\n",
    "print(\"New Weights:\", new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
